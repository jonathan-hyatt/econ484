{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brighamfrandsen/econ484/blob/master/examples/tweet%20demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3ETn1Dp40gO"
      },
      "source": [
        "First some preliminaries. Import some useful packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylgX-ixv40gS"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/brighamfrandsen/econ484.git\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import tree\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFXzPP_40gU"
      },
      "source": [
        "    more prelims"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH72rSHj40gV"
      },
      "source": [
        "Read in raw data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHW8V3ku40gV"
      },
      "outputs": [],
      "source": [
        "# reading in the data\n",
        "obama = pd.read_csv('econ484/data/obama_tweets.csv')\n",
        "trump = pd.DataFrame(json.load(open('econ484/data/trump_tweets.json',encoding='utf8')))\n",
        "\n",
        "print(obama.head())\n",
        "print(trump.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yR2uMQn40gW"
      },
      "outputs": [],
      "source": [
        "# adding obama indicator\n",
        "obama['obama_indicator'] = 1\n",
        "trump['obama_indicator'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj0wav3i40gW"
      },
      "source": [
        "some data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oAt8aDA40gW"
      },
      "outputs": [],
      "source": [
        "# Renaming columns to make them consistent for concatenation\n",
        "obama.rename(columns={'Text': '_text'}, inplace=True)\n",
        "trump.rename(columns={'text': '_text'}, inplace=True)\n",
        "\n",
        "# Concatenating the two datasets\n",
        "both = pd.concat([obama.loc[:, ['_text', 'obama_indicator']],\n",
        "                  trump.loc[:, ['_text', 'obama_indicator']]])\n",
        "\n",
        "# Dropping retweets\n",
        "both = both.loc[~both._text.str.contains('^RT'), :]\n",
        "print('Shape of raw data:', both.shape)\n",
        "\n",
        "# Cleaning the text\n",
        "both['_text'] = both['_text'].str.strip()\n",
        "\n",
        "# Replace sequences\n",
        "both['_text'] = both['_text'].replace({\n",
        "    r'\\s+': ' ',                       # Removing extra spaces\n",
        "    r'(?:: )?https?://\\S+': '',         # Removing URLs\n",
        "    r'\\.?pic\\.twitter\\.com/\\S+': '',    # Removing Twitter image links\n",
        "    r'\\d+': '',                         # Removing digits\n",
        "    r'[…\"#$%&\\'\\(\\)*+,-./:;<=>?@\\[\\\\\\]^_`{|}~’“”—]': '',  # Removing punctuation\n",
        "    r'–|––|\\s+': ' '                   # Normalizing dashes and extra spaces\n",
        "}, regex=True)\n",
        "\n",
        "# Count the number of capital letters before converting to lowercase\n",
        "both['n_cap_let'] = both['_text'].apply(lambda x: len(re.findall('[A-Z]', x)))\n",
        "\n",
        "# Converting the text to lowercase\n",
        "both['_text'] = both['_text'].str.lower()\n",
        "\n",
        "# Removing specific words related to the context\n",
        "remove_words = ['trump', 'president obama', 'obama', 'barack', 'michelle', 'amp', 'ofa']\n",
        "for word in remove_words:\n",
        "    both['_text'] = both['_text'].str.replace(word, '', regex=False)\n",
        "\n",
        "# Tokenizing the text\n",
        "tknzr = TweetTokenizer()\n",
        "both['tokens'] = both['_text'].apply(lambda x: [re.sub('_', '', y) for y in tknzr.tokenize(x)])\n",
        "\n",
        "# Dropping rows with empty tokens after cleaning\n",
        "both = both.loc[both['tokens'].apply(lambda x: len(x) > 0), :]\n",
        "\n",
        "# Generating feature variables\n",
        "both['total_words'] = both['tokens'].apply(len)\n",
        "both['avg_word_len'] = both['tokens'].apply(lambda x: sum(len(y) for y in x) / len(x) if len(x) > 0 else 0)\n",
        "\n",
        "print(\"Data cleaned and features generated...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NErCExH940gX"
      },
      "source": [
        "generate features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA4BCvWf40gX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(max_df=.5, min_df=.0001, stop_words='english', tokenizer=tknzr.tokenize,\n",
        "                                 ngram_range=(1, 3))\n",
        "bow_mat = vectorizer.fit_transform(both._text)\n",
        "print('Bag of words feature set:', bow_mat.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLWCBhoc40gX"
      },
      "source": [
        "get ready to model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpTf4LU-40gY"
      },
      "outputs": [],
      "source": [
        "# modelling\n",
        "dtree = tree.DecisionTreeClassifier(random_state=123,max_depth=2)\n",
        "dtree.fit(bow_mat, both.obama_indicator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-YOpDNX40gY"
      },
      "outputs": [],
      "source": [
        "# visualize decision tree\n",
        "tree.plot_tree(dtree, feature_names=vectorizer.get_feature_names_out() ,filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHa9wYo340gZ"
      },
      "source": [
        "Try a new tweet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt412CYv40gZ"
      },
      "outputs": [],
      "source": [
        "new_tweet='Congrats to our newest class of foundation scholars. These leaders are working to change their communities for the better'\n",
        "new_feats=vectorizer.transform([new_tweet])\n",
        "dtree.predict_proba(new_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvIxTvwO40gZ"
      },
      "outputs": [],
      "source": [
        "print(new_feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YMyZLt-40gZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
